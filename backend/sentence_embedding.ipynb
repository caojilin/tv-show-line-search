{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "# sentences = [\n",
    "#     \"The weather is lovely today.\",\n",
    "#     \"It's so sunny outside!\",\n",
    "#     \"He drove to the stadium.\"\n",
    "# ]\n",
    "# embeddings = model.encode(sentences)\n",
    "# similarities = model.similarity(embeddings, embeddings)\n",
    "# print(similarities.shape)\n",
    "# # [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./intfloat/multilingual-e5-large-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the folder where this script is located\n",
    "# df = pd.read_csv(\"schrute.csv\", header=0)\n",
    "# print(df.columns)\n",
    "# df['lower'] = df['text'].str.lower()\n",
    "# df['lower'] = df['lower'].str.strip()\n",
    "# # Replace empty strings with NaN and then drop those rows\n",
    "# df.replace(pd.NA, \"\", inplace=True)\n",
    "# sentences = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TBBT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['index',\n",
    "#  'season',\n",
    "#  'episode',\n",
    "#  'episode_name',\n",
    "#  'director',\n",
    "#  'writer',\n",
    "#  'character',\n",
    "#  'text',\n",
    "#  'text_w_direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"TBBT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = df['text'].tolist()\n",
    "# all_embeddings = []\n",
    "# for i in range(0, len(df['text']), 10000):\n",
    "#     print(i, i+10000)\n",
    "#     embeddings = model.encode(sentences[i:i+10000])\n",
    "#     all_embeddings.append(embeddings)\n",
    "# combined_vertical = np.vstack(all_embeddings)\n",
    "# # Step 2: Pickle the array\n",
    "# with open('TBBT.pkl', 'wb') as f:\n",
    "#     pickle.dump(combined_vertical, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Property Division Collision'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['season'] == 10) & (df['episode']==10)]['episode_name'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for season in range(1,11):\n",
    "    obj = {\n",
    "    \"title\": f\"season {season}\",\n",
    "    \"value\": f\"{season}\",\n",
    "    \"selectable\": False,\n",
    "    \"children\": []\n",
    "  }\n",
    "    children = []\n",
    "    max_episode = max(df[df['season'] == season]['episode'])\n",
    "    for episode in range(1, max_episode+1):\n",
    "      episode_name = df[(df['season'] == season) & (df['episode']==episode)]['episode_name'].unique()[0]\n",
    "      children.append({ \"title\": f\"season {season} episode {episode} - {episode_name}\", \"value\": f\"{season}-{episode}\" }  )\n",
    "    obj[\"children\"] = children\n",
    "    data.append(obj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"season_episode.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"data.json\", orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Unpickle the array\n",
    "with open('combined_vertical.pkl', 'rb') as f:\n",
    "    combined_vertical = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Bears, beets, Battlestar Galactica.\"\n",
    "query = \"out of your hands\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10067, 52462, 39578, 39570, 26538, 8992, 26537, 39557, 5480, 38165]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.similarity(query_embedding, combined_vertical)[0]\n",
    "indices = np.argsort(scores).tolist()[::-1][:10]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                         2\n",
       "season                                                        1\n",
       "episode                                                       1\n",
       "episode_name                                              Pilot\n",
       "director                                             Ken Kwapis\n",
       "writer              Ricky Gervais;Stephen Merchant;Greg Daniels\n",
       "character                                                   Jim\n",
       "text                 Oh, I told you. I couldn't close it. So...\n",
       "text_w_direction     Oh, I told you. I couldn't close it. So...\n",
       "lower                oh, i told you. i couldn't close it. so...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10067    Your hands.\n",
       "52462    Put it down\n",
       "39578               \n",
       "39570               \n",
       "26538               \n",
       "8992                \n",
       "26537               \n",
       "39557               \n",
       "5480                \n",
       "38165               \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[indices]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "with open('the_office.pkl', 'rb') as f:\n",
    "        vector_stacked = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('schrute.csv')\n",
    "# query = \"did you also hand in\"\n",
    "query = \"did you also hand in two\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 55127, 55128, 55129])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_indices = np.arange(len(df))\n",
    "original_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['text'].tolist()\n",
    "a = np.array([x if x is not None else \"\" for x in a])  # Replace None with empty strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True, False,  True])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.vectorize(len)(a) >= len(query)  # Boolean mask for valid strings\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vectors = vector_stacked[mask]\n",
    "filtered_indices = original_indices[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55130, 34134, 34134)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_stacked), len(filtered_vectors), len(filtered_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n",
      "That was meant for Kelly.\n",
      "6788\n",
      "One, two.. Didn't say three, did I?\n",
      "28636\n",
      "I can name Pixar movies, too. Toy Story.\n",
      "46424\n",
      "Did you wash your hands?\n",
      "22588\n",
      "Anyone else?\n",
      "36801\n",
      "Two for two, keep it up.\n",
      "2815\n",
      "Fantastic!\n",
      "4649\n",
      "Yes, you did. What is wrong with you?\n",
      "2202\n",
      "Now the bronze are really blue, and they're also the back side of the gold, so no flipping. K? Honor system.\n",
      "3613\n",
      "And, um, one down. Next suggestion\n"
     ]
    }
   ],
   "source": [
    "scores = model.similarity(query_embedding, filtered_vectors)[0]\n",
    "indices = np.argsort(scores).tolist()[::-1][:5]\n",
    "for i in indices:\n",
    "    print(i)\n",
    "    print(df.loc[i]['text'])\n",
    "    print(filtered_indices[i])\n",
    "    print(df.loc[filtered_indices[i]]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38996\n",
      "You did approve it?\n",
      "27425\n",
      "You did?\n",
      "18456\n",
      "You did?\n",
      "37576\n",
      "You did?\n",
      "5968\n",
      "You did?\n"
     ]
    }
   ],
   "source": [
    "scores = model.similarity(query_embedding, vector_stacked)[0]\n",
    "indices = np.argsort(scores).tolist()[::-1][:5]\n",
    "for i in indices:\n",
    "    print(i)\n",
    "    print(df.loc[i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
